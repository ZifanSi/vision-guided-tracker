% THIS DOCUMENT IS FOLLOWS THE VOLERE TEMPLATE BY Suzanne Robertson and James Robertson
% ONLY THE SECTION HEADINGS ARE PROVIDED
%
% Initial draft from https://github.com/Dieblich/volere
%
% Risks are removed because they are covered by the Hazard Analysis
\documentclass[12pt]{article}
\pdfinfoomitdate=1
\pdftrailerid{}

\usepackage{booktabs}
\usepackage{tabularx}
\usepackage{hyperref}
\usepackage{enumitem}
\hypersetup{
    bookmarks=true,         % show bookmarks bar?
    colorlinks=true,        % false: boxed links; true: colored links
    linkcolor=red,          % color of internal links (change box color with linkbordercolor)
    citecolor=green,        % color of links to bibliography
    filecolor=magenta,      % color of file links
    urlcolor=cyan           % color of external links
}

\newcommand{\lips}{\textit{Insert your content here.}}

\input{../Comments}
\input{../Common}

\begin{document}

\title{Software Requirements Specification for \progname: High Performance Vision-Guided Rocket Tracker}
\author{\authname}
\date{\today}

\maketitle

~\newpage

\tableofcontents

~\newpage

\section*{Revision History}

\begin{tabularx}{\textwidth}{p{3cm}p{2cm}X}
  \toprule {\textbf{Date}} & {\textbf{Version}} & {\textbf{Notes}} \\
  \midrule
  Date 1                   & 1.0                & Notes            \\
  Date 2                   & 1.1                & Notes            \\
  \bottomrule
\end{tabularx}

~\\

~\newpage
\section{Purpose of the Project}
\subsection{User Business}

Student and amateur rocketry teams, launch organizers, and technical judges
need reliable, high-fidelity visual evidence of rocket flights to analyze
staging behavior, parachute deployment, and flight anomalies that occur at
extreme speeds and altitudes. Manual camera operation is impractical in these
conditions, and existing tools (manual PTZ/GPS-centric systems) often fail to
maintain visual lock on small, fast-moving vehicles. The project addresses this
gap with an autonomous, vision-based tracking camera designed to lock onto and
follow rockets from launch through early descent, providing real-time and
recorded footage for post-flight analysis and event operations.

Beyond a single event, the system is intended to integrate into ground
operations for student and commercial launches, strengthening Canada’s student
rocketry and broader aerospace ecosystem by improving diagnostics,
documentation, and training outcomes.

From a commercialization lens, the solution targets academic rocketry
competitions first (where capable tracking is scarce or costly), then expands
toward high-power amateur and small-launch markets. Differentiation rests on
fully autonomous visual tracking and robust re-identification under sub-optimal
conditions, opening paths to kit/service offerings and SaaS add-ons (cloud
analytics, model updates).

\subsection{Goals of the Project}

The goal of the project is to track small-scale model rocket launches with
apogee \textless 200m, while achieving all the performance objectives.

\section{Stakeholders}

\subsection{Client}

The client of this project is McMaster Rocketry Team. they are the primary end
users who will deploy the system during launches. They depend on accurate
real-time tracking to analyze staging, parachute deployment, and overall flight
performance.

\subsection{Customer}

\begin{enumerate}
  \item \textbf{Aerospace Engineers and Researchers}: Benefit from
        high-quality flight footage to validate models, improve rocket
        designs, and support experimental research.

  \item \textbf{Event Organizers and Safety Officers}: Rely on
        reliable tracking for live monitoring of rocket flights,
        particularly for confirming parachute deployment and safe
        recovery during launch events.

  \item \textbf{Engineering and Robotics Community}: May adapt the
        system's design principles for other domains requiring precise
        tracking of fast-moving objects, such as UAV navigation, sports
        analytics, or autonomous robotics.

  \item \textbf{Potential Commercial and Industrial Users}: Could
        adopt the system for broader applications in surveillance,
        wildlife monitoring, or industrial inspections where real-time
        vision-guided tracking is valuable.
\end{enumerate}

\subsection{Other Stakeholders}

\begin{enumerate}
  \item \textbf{Dr. Shahin Sirouspour (Supervisor)}: Provides
        technical guidance, project oversight, and mentorship. Ensures
        the project aligns with academic standards, engineering best
        practices, and capstone deliverable expectations.
\end{enumerate}

\subsection{Hands-On Users of the Project}

The only hands on user of the project would be the camera operator, which can
be any one of the stakeholders or anyone else tasked by one of the
stakeholders. The camera operator controls the camera through the UI,
starts/stops recordings, manages lock-on/target selection, and monitors
preview.

\subsection{Personas}

\subsubsection*{Alex Chen}

\textbf{Age}: 22

\textbf{Job Title}: Camera Operator

\textbf{Education}: B.Eng. candidate (Electrical/Mechatronics)

\textbf{Work Environment}: Outdoor launch range; tripod/gimbal on uneven terrain;
laptop/tablet UI at the ground station; radio comms with Mission Control.

\textbf{Professional Background}: Operates field equipment for the rocketry team; basic
Linux/Jetson administration; familiar with gimbals, lens swaps, focus checks,
and safety procedures.

\textbf{Need}: Fast setup and calibration; immediate lock-on
after launch cue; low-latency preview that stays readable in bright sunlight;
simple controls for start/stop recording and target selection; clear
system-state indicators (ready/locked/error).

\textbf{Challenges}: Harsh conditions
(wind, glare, dust, cold); intermittent power/network; gloves reduce fine
control; pressure at T-0; distance from pad complicates cabling; strict range
safety rules.

\subsubsection*{Maya Patel}

\textbf{Age}: 24

\textbf{Job Title}: Flight Performance Analyst (Rocketry Team)

\textbf{Education}: B.Eng. (Software/Controls) or Honours Physics; heavy MATLAB/Python use

\textbf{Work Environment}: Post-flight lab analysis; imports footage + telemetry into scripts and reports.

\textbf{Professional Background}: Builds tooling to study staging timing, parachute events, and stability; integrates video with onboard logs.

\textbf{Need}: Time-synchronized 1080p60 footage with frame timestamps; exports of gimbal azimuth/elevation vs. time (CSV/JSON); markers for detected events (ignition, staging, chute) and easy clip extraction; consistent file naming and metadata for repeatable analyses.

\textbf{Challenges}: Clock drift between video and sensors; dropped frames; incomplete metadata; inconsistent camera calibration notes; large file sizes slowing transfer and processing.

\subsubsection*{Jordan Lee}

\textbf{Age}: 59

\textbf{Job Title}: Event Organizer / Live Stream Technician

\textbf{Education}: College diploma or industry certifications (broadcast/AV)

\textbf{Work Environment}: Control tent; HDMI/SDI switcher or OBS rig; long Ethernet runs; noisy RF environment.

\textbf{Professional Background}: Manages livestreams at student launches; coordinates feeds from multiple cameras to a program output.

\textbf{Need}: Clean 1080p60 video feed compatible with common switchers/encoders; stable, low end-to-end latency preview; obvious health/status indicators; quick, safe setup between flights; minimal operator steps to get a reliable program feed.

\textbf{Challenges}: RF congestion and interference; power distribution limits; weatherproofing; cable management over long distances; ensuring the tracking feed doesn’t drop mid-event; coordinating with safety calls and launch cadence.

\subsection{Priorities Assigned to Users}

\textbf{Key Users}: Flight Performance Analyst, Safety Officer, Camera Operator

\textbf{Secondary User}: Event Organizer

\subsection{User Participation}

Through out the development process, the development team will reach out to
users to gather requirements and feedback on usability.

\subsection{Maintenance Users and Service Technicians}

Due to the nature of this project as a capstone requirement, there are
currently no expected maintenance users

\section{Mandated Constraints}
\subsection{Solution Constraints}

\begin{enumerate}[label=MD-SL \arabic*., wide=0pt, leftmargin=*]
  \item \emph{The system must be hands-off (autonomous) from ignition through rocket landing.}\\[2mm]
        {\bf Rationale:} During live launches, human operators must prioritize range safety and situational awareness; approaching the camera or issuing fine controls during ascent/descent is unsafe and impractical due to line-of-sight, blast hazards, and rapid dynamics. Environmental factors (wind, glare, dust, acoustic vibration) also degrade manual operation at critical moments.\\
        {\bf Fit Criterion:} From ignition detection until a declared “landing/clear” signal, the system performs target detection, tracking, zoom/FOV management, and recording without requiring any manual pan/tilt/zoom commands. Event logs show no manual overrides in this window; tracked target remains within a defined bounding box around frame center (e.g., ±10\% of width/height) for $\ge$80\% of observable flight time.

  \item \emph{The system must be remote controllable.}\\[2mm]
        {\bf Rationale:} The camera and gimbal may need to be positioned near hazardous zones (pad, ballistic landing corridors) or at distant vantage points with no safe operator access during the countdown and flight. Remote setup, arming, health checks, and teardown reduce personnel exposure and allow operation from a protected control area.\\
        {\bf Fit Criterion:} All pre-/post-flight operations (boot, status, calibration checks, arming, recording start/stop, data offload) are executable over a network link (wired or long-run Ethernet) from the control station. Authentication is required; a complete session can be performed with no physical interaction at the camera site once deployed.

  \item \emph{The system must output a live video stream via HDMI.}\\[2mm]
        {\bf Rationale:} The event’s broadcast/recording workflow and on-site switchers/encoders accept HDMI as the integration standard; alternative connectors (e.g., SDI/USB/UVC-only) would require additional, failure-prone adapters and complicate field cabling.\\
        {\bf Fit Criterion:} A stable, clean (non-OSD) HDMI program feed at 1920×1080@60\,fps is available at the control station for the duration of the launch window. The feed syncs with common mixers/encoders (e.g., OBS/capture cards) without HDCP or proprietary handshakes and remains within acceptable glass-to-glass latency for live use.

  \item \emph{The solution must provide a flexible interface to support multiple gimbal systems.}\\[2mm]
        {\bf Rationale:} Different test contexts require different hardware: lighter indoor rigs for algorithm development, weatherized outdoor rigs for launches, and varying payload (camera/lens) masses. A hardware-abstraction layer reduces rework and enables swapping gimbals without changing core tracking logic.\\
        {\bf Fit Criterion:} A documented gimbal adapter interface (API/protocol bindings) supports at least: (a) an indoor development gimbal, (b) an outdoor launch-capable gimbal, and (c) a higher-payload option. For each, the system can command pan/tilt/zoom, read state, and complete calibration; end-to-end control latency remains within the tracking budget, and per-gimbal mounting/calibration data can be loaded without code changes.
\end{enumerate}

\subsection{Implementation Environment of the Current System}

There are no constrains on the hardware platform the project need to use or run
on.

\subsection{Partner or Collaborative Applications}

none

\subsection{Off-the-Shelf Software}

none

\subsection{Anticipated Workplace Environment}

what is this?

\subsection{Schedule Constraints}

\begin{enumerate}[label=SCHD \arabic*., wide=0pt, leftmargin=*]
  \item \emph{The project shall be completed by April 2026, with
          interim deadlines for key milestones such as Proof of Concept
          (November 2025) and the final demonstration (March 2026).}\\[2mm]
        {\bf Rationale:} These deadlines are based on the academic
        timeline and the expectations of the capstone course.\\
        {\bf Fit Criterion:} All project components must be completed and
        fully functional by the final demonstration in March 2026.
\end{enumerate}

\subsection{Budget Constraints}

\begin{enumerate}[label=BDGT \arabic*., wide=0pt, leftmargin=*]
  \item \emph{The project shall not exceed the budget of 500CAD}\\[2mm]
        {\bf Rationale:} Limited by the capstone project requirement\\
        {\bf Fit Criterion:} The project must be implemented using free
        tools and libraries and hosted on GitHub.
\end{enumerate}

\subsection{Enterprise Constraints}

\begin{enumerate}[label=ENTP \arabic*., wide=0pt, leftmargin=*]
  \item \emph{The product shall be built to comply with the standards
          of McMaster University's capstone project requirements and
          academic integrity policies.}\\[2mm]
        {\bf Rationale:} The project is part of the university's
        curriculum and must adhere to its standards.\\
        {\bf Fit Criterion:} The product must meet the requirements
        specified by the course syllabus and project advisor.
\end{enumerate}

\section{Naming Conventions and Terminology}
\subsection{Glossary of All Terms, Including Acronyms, Used by Stakeholders
  involved in the Project}
\lips

\section{Relevant Facts And Assumptions}
\subsection{Relevant Facts}

not applicable

\subsection{Business Rules}

not applicable

\subsection{Assumptions}

not applicable

\section{The Scope of the Work}
\subsection{The Current Situation}
\lips
\subsection{The Context of the Work}
\lips
\subsection{Work Partitioning}
\lips
\subsection{Specifying a Business Use Case (BUC)}
\lips

\section{Business Data Model and Data Dictionary}
\subsection{Business Data Model}
\lips
\subsection{Data Dictionary}
\lips

\section{The Scope of the Product}
\subsection{Product Boundary}
\lips
\subsection{Product Use Case Table}
\lips
\subsection{Individual Product Use Cases (PUC's)}
\lips

\section{Functional Requirements}
\subsection{Functional Requirements}

\begin{itemize}

  \item[FR-SYS-1] \emph{The system must acquire live images or video streams from an onboard camera.}\\[2mm]
    {\bf Rationale:} Image acquisition is the first step of the vision-guided pipeline and enables all downstream processing.\\
    {\bf Fit Criterion:} The system successfully captures frames at a usable resolution and passes them to the CV pipeline.\\
    {\bf Priority:} High

  \item[FR-SYS-2] \emph{The system must segment the scene and detect multiple moving objects in real time.}\\[2mm]
    {\bf Rationale:} Object detection enables the tracker to identify possible targets for selection and tracking.\\
    {\bf Fit Criterion:} At least two moving objects can be detected simultaneously at $\geq$ 15 FPS on Jetson hardware.\\
    {\bf Priority:} High

  \item[FR-SYS-3] \emph{The system must allow the operator to select a stationary or moving object as the target.}\\[2mm]
    {\bf Rationale:} Manual target selection is essential for flexibility, ensuring the system can track user-specified objects.\\
    {\bf Fit Criterion:} Operator input is received and the chosen target is registered by the tracking system.\\
    {\bf Priority:} High

  \item[FR-SYS-4] \emph{The system must continuously estimate the target’s position and keep it centered in the image.}\\[2mm]
    {\bf Rationale:} Accurate target tracking is the core function of the system to maintain visual lock.\\
    {\bf Fit Criterion:} Target remains within 40 px of frame center at 1080p resolution under smooth motion.\\
    {\bf Priority:} High

  \item[FR-SYS-5] \emph{The system must send real-time pan/tilt commands to the STM32 microcontroller for gimbal control.}\\[2mm]
    {\bf Rationale:} Gimbal control keeps the target centered physically, extending camera field of view.\\
    {\bf Fit Criterion:} Latency between detected movement and gimbal adjustment is $\leq$ 120 ms.\\
    {\bf Priority:} High

  \item[FR-SYS-6] \emph{The system must detect target occlusion or loss and attempt automatic re-acquisition, with manual reselection available.}\\[2mm]
    {\bf Rationale:} Targets may be temporarily obstructed; recovery ensures robustness of the tracking loop.\\
    {\bf Fit Criterion:} The system reacquires a target within 1 second (p95) or allows operator reselection.\\
    {\bf Priority:} Medium

  \item[FR-SYS-7] \emph{The system must provide remote management capabilities for operators.}\\[2mm]
    {\bf Rationale:} Remote access supports field deployment and safety by allowing off-device control.\\
    {\bf Fit Criterion:} Operators can access system controls via a web interface on a remote device.\\
    {\bf Priority:} Medium

  \item[FR-SYS-8] \emph{The system must display runtime information including system state, FPS, and tracking status.}\\[2mm]
    {\bf Rationale:} Visibility into runtime performance is critical for debugging and operator trust.\\
    {\bf Fit Criterion:} The interface updates system status in real time with FPS $\pm$ 1 frame accuracy.\\
    {\bf Priority:} Medium

  \item[FR-SYS-9] \emph{The system must demonstrate the complete workflow: Acquire $\rightarrow$ Detect $\rightarrow$ Select $\rightarrow$ Track $\rightarrow$ Control.}\\[2mm]
    {\bf Rationale:} The proof-of-concept requires showing the integration of all subsystems working together.\\
    {\bf Fit Criterion:} During demo, the system executes all five stages successfully without manual patching.\\
    {\bf Priority:} High

% --- Web End Requirements ---
\item[FR-WEB-1] \emph{The web application must provide a browser-based interface for remote management of the system.}\\[2mm]
  {\bf Rationale:} Operators need remote access to safely configure and monitor the system during field testing.\\
  {\bf Fit Criterion:} Operators can log in through a standard browser and access system controls without requiring local installation.\\
  {\bf Priority:} Medium

\item[FR-WEB-2] \emph{The web application must display runtime status information such as system state, frame rate, and tracking status.}\\[2mm]
  {\bf Rationale:} Operators need real-time visibility into performance to make informed decisions and detect issues.\\
  {\bf Fit Criterion:} The dashboard shows current state, FPS, and tracking status, updating within 1 second of backend changes.\\
  {\bf Priority:} Medium

\item[FR-WEB-3] \emph{The web application must provide controls for manual target reselection when automatic tracking fails.}\\[2mm]
  {\bf Rationale:} Manual override enables recovery when auto-reacquisition is unsuccessful.\\
  {\bf Fit Criterion:} When a target is lost, the operator can reselect a target via the web UI and the system resumes tracking within 1 second.\\
  {\bf Priority:} High

\item[FR-WEB-4] \emph{The web application must allow operators to view the live video stream from the camera.}\\[2mm]
  {\bf Rationale:} Visual confirmation of what the system is tracking is necessary for effective operation.\\
  {\bf Fit Criterion:} The live camera feed is viewable in the web interface with end-to-end latency $\leq$ 500 ms relative to the source.\\
  {\bf Priority:} High

\item[FR-WEB-5] \emph{The web application must allow operators to record video sessions for later review.}\\[2mm]
  {\bf Rationale:} Recording supports debugging, validation, and demonstration.\\
  {\bf Fit Criterion:} Operators can start and stop recording from the web UI and access the saved video files afterward.\\
  {\bf Priority:} Medium

\item[FR-WEB-6] \emph{The web application must provide playback and basic management of recorded videos (list, delete, download).}\\[2mm]
  {\bf Rationale:} Reviewing and managing captured sessions supports performance analysis and documentation.\\
  {\bf Fit Criterion:} Operators can select a recording, play it in the web UI, and perform list/delete/download actions.\\
  {\bf Priority:} Low



\end{itemize}





\section{Look and Feel Requirements}
\subsection{Appearance Requirements}
\begin{itemize}[leftmargin=*]
  \item[LFR-AP-1] \emph{The dashboard shall use a light background with high-contrast status colors (green=Ready, amber=Armed, red=Fault/Lost).}\\
  \textbf{Rationale:} Improves readability under bright outdoor lighting and noisy environments.\\
  \textbf{Fit Criterion:} In a 300-lux outdoor setting, at least 19 out of 20 status checks by five users are correctly identified within 2 seconds.

  \item[LFR-AP-2] \emph{Key readouts (FPS, end-to-end latency estimate, tracking confidence) shall be visible in the main view without scrolling on a 1080p display.}\\
  \textbf{Rationale:} Operators need immediate awareness of system health and tracking quality.\\
  \textbf{Fit Criterion:} On a 1920×1080 monitor, all three readouts are simultaneously visible in the primary screen.
\end{itemize}

\subsection{Style Requirements}
\begin{itemize}[leftmargin=*]
  \item[LFR-ST-1] \emph{Units and terminology shall be consistent: speed (°/s), resolution (px), frame rate (FPS), distance (km), temperature (°C).}\\
  \textbf{Rationale:} Consistency reduces operator error during high-pressure launch operations.\\
  \textbf{Fit Criterion:} A style audit of 10 UI readouts finds zero unit inconsistencies.
\end{itemize}

\section{Usability and Humanity Requirements}
\subsection{Ease of Use Requirements}
\begin{itemize}[leftmargin=*]
  \item[USR-EZ-1] \emph{Cold start to “Ready” shall require no more than five operator steps; reset between launches shall be $\leq$ 2 minutes.}\\
  \textbf{Rationale:} Field workflow demands rapid setup, turnaround, and minimal touches at the pad.\\
  \textbf{Fit Criterion:} Three operators independently achieve average reset time $\leq$ 120 s and $\leq$ 5 steps from cold start to “Ready”.

  \item[USR-EZ-2] \emph{The full operational flow (power on, checks, arm, record, shutdown) shall be executable remotely without visiting the camera site.}\\
  \textbf{Rationale:} Reduces exposure to hazardous zones and supports protected control-tent operation.\\
  \textbf{Fit Criterion:} A complete session is performed from the control station with zero physical interaction at the camera.
\end{itemize}


\subsection{Personalization and Internationalization Requirements}
\begin{itemize}[leftmargin=*]
  \item[USR-PI-1] \emph{The user interface shall support English and French(chinese), switchable at runtime.}\\
  \textbf{Rationale:} Matches Canadian event context and bilingual stakeholders.\\
  \textbf{Fit Criterion:} All primary UI elements are fully localized for EN/FR/CN; language can be switched without restart.
\end{itemize}

\subsection{Learning Requirements}
\begin{itemize}[leftmargin=*]
  \item[USR-LR-1] \emph{A first-time operator shall be able to complete a full run in “Simulation Input Mode” within 30 minutes.}\\
  \textbf{Rationale:} Simulation accelerates training and reduces field risk.\\
  \textbf{Fit Criterion:} Three novice users complete the simulated end-to-end flow in $\leq$ 30 minutes each.
\end{itemize}

\subsection{Understandability and Politeness Requirements}
\begin{itemize}[leftmargin=*]
  \item[USR-UP-1] \emph{Alerts shall include both the cause and an actionable suggestion (e.g., “Tracking lost: try manual reselect”).}\\
  \textbf{Rationale:} Reduces cognitive load and speeds recovery.\\
  \textbf{Fit Criterion:} Five sampled alert types each contain a cause and a next-step recommendation.
\end{itemize}

\subsection{Accessibility Requirements}
\begin{itemize}[leftmargin=*]
  \item[USR-AC-1] \emph{Minimum text size shall be 12\,pt; critical readouts shall be $\geq$16\,pt; status indicators shall remain distinguishable under common color-vision deficiencies.}\\
  \textbf{Rationale:} Ensures legibility for diverse users and conditions.\\
  \textbf{Fit Criterion:} UI passes color-vision simulations and size checks in a design audit.
\end{itemize}

\section{Performance Requirements}
\subsection{Speed and Latency Requirements}
\begin{itemize}[leftmargin=*]
  \item[PR-SPD-1] \emph{End-to-end live streaming latency shall be $\leq$ 300\,ms (p95); on-device preview latency shall be $\leq$ 100\,ms (p95).}\\
  \textbf{Rationale:} Live production and manual intervention depend on low latency.\\
  \textbf{Fit Criterion:} Time-synchronized probes confirm p95 $\leq$ 300\,ms (glass-to-glass) and p95 $\leq$ 100\,ms (local preview).

  \item[PR-SPD-2] \emph{AI inference latency per frame shall be $\leq$ 50\,ms (p95) at the target resolution.}\\
  \textbf{Rationale:} Keeps the track-control loop within the motion budget.\\
  \textbf{Fit Criterion:} Profiling at the specified model/resolution shows p95 $\leq$ 50\,ms.
\end{itemize}
\subsection{Safety-Critical Requirements}
\lips
\subsection{Precision or Accuracy Requirements}
\lips
\subsection{Robustness or Fault-Tolerance Requirements}
\lips
\subsection{Capacity Requirements}
\lips
\subsection{Scalability or Extensibility Requirements}
\lips
\subsection{Longevity Requirements}
\lips

\section{Operational and Environmental Requirements}
\subsection{Expected Physical Environment}
\lips
\subsection{Wider Environment Requirements}
\lips
\subsection{Requirements for Interfacing with Adjacent Systems}
\lips
\subsection{Productization Requirements}
\lips
\subsection{Release Requirements}
\lips

\section{Maintainability and Support Requirements}
\subsection{Maintenance Requirements}
\lips
\subsection{Supportability Requirements}
\lips
\subsection{Adaptability Requirements}
\lips

\section{Security Requirements}
\subsection{Access Requirements}
\lips
\subsection{Integrity Requirements}
\lips
\subsection{Privacy Requirements}
\lips
\subsection{Audit Requirements}
\lips
\subsection{Immunity Requirements}
\lips

\section{Cultural Requirements}
\subsection{Cultural Requirements}
\lips

\section{Compliance Requirements}
\subsection{Legal Requirements}
\lips
\subsection{Standards Compliance Requirements}
\lips

\section{Open Issues}
\lips

\section{Off-the-Shelf Solutions}
\subsection{Ready-Made Products}
\lips
\subsection{Reusable Components}
\lips
\subsection{Products That Can Be Copied}
\lips

\section{New Problems}
\subsection{Effects on the Current Environment}
\lips
\subsection{Effects on the Installed Systems}
\lips
\subsection{Potential User Problems}
\lips
\subsection{Limitations in the Anticipated Implementation Environment That May
  Inhibit the New Product}
\lips
\subsection{Follow-Up Problems}
\lips

\section{Tasks}
\subsection{Project Planning}
\lips
\subsection{Planning of the Development Phases}
\lips

\section{Migration to the New Product}
\subsection{Requirements for Migration to the New Product}
\lips
\subsection{Data That Has to be Modified or Translated for the New System}
\lips

\section{Costs}
\lips
\section{User Documentation and Training}
\subsection{User Documentation Requirements}
\lips
\subsection{Training Requirements}
\lips

\section{Waiting Room}
\lips

\section{Ideas for Solution}
\lips

\newpage{}
\section*{Appendix --- Reflection}

\input{../Reflection.tex}

\input{../SRS_Reflection.tex}

\end{document}